#!/bin/env bash
trap sig_abort SIGINT
start=`date +%s`
ARGS='--connect-timeout 5 --max-time 10 --retry 5 --retry-delay 0 --retry-max-time 40 -ks'; LOCAL="persie"
DIR=~/.turbodl; PXLS=(360 480 540 720 1080 2160);
mkdir -p $DIR/movies $DIR/series $DIR/logs $DIR/junk; cd "$DIR"; JUNK=junk
find . ! -name '*list' -type f -exec rm -rf {} +
if [ "$USER" != "$LOCAL" ]; then cat ~/turbodl/list > $DIR/list; else cat ~/git/turbodl/list > $DIR/list; fi
printf %b ":: working...\\r"
case "$1" in
    '') exit;;
    -l|--lightdl)
        shift; echo -e "https://lightdlmovies.blogspot.com/search/label/MOVIES" > $JUNK/url
        for PARAM; do grep ^'%' <<< "$PARAM" | sed 's/%/^/' >> $JUNK/pattern; done;;
    -u|--url)
        shift
        for PARAM; do grep 'http' <<< "$PARAM" >> $JUNK/url || grep ^'%' <<< "$PARAM" | sed 's/%/^/' >> $JUNK/pattern; done
        ;;
    *)  exit;;
esac
touch $JUNK/file $JUNK/pid $JUNK/pids
(while IFS= read -r "U"; do
    if grep -q "lightdl" <<< "$U"; then
        #download page and extract post links
        curl $ARGS "$U" | grep -Eo "http(|s).*html.*title=.*</a>" | sed 's:</a>.*::' > $JUNK/main || exit
    elif grep -q "twitchdl" <<< "$U"; then
        curl $ARGS "$U" | grep -Eo "http(|s).*html.*</a>" | sed 's:</a>.*::; /Series/d; /Movies/d; /-list/d; /href/d; /covid-19/d; /jpg/d; /Share this/d; /releases/d; /vals-day/d; /Read More/d; /search/d; / [0-9][0-9][0-9][0-9] HD/d; / [0-9][0-9][0-9][0-9]/d' > "$JUNK/main" || exit
    fi
    grep -n . $JUNK/main > $JUNK/mains; mv $JUNK/mains $JUNK/main   #number list of movies in main file
    if grep -q -- "--list" <<< "$@"; then   #if statement to list movies and end
        printf %b "             \\r"; cat $JUNK/main | sed 's:http.*>::' && sig_abort
    fi
    if [ -e $JUNK/pattern ] && [ $(wc -l<$JUNK/pattern) -gt 0 ]; then
        output=$(grep -w -f $JUNK/pattern $JUNK/main | sed "s:.*>::; s: - SEASON.*::")
    else
        output=$(sed "s:.*>::; s: - SEASON.*::; s: - Season.*::" "$JUNK/main")
    fi
    (while IFS= read -r "OUTPUT"; do
        ! grep -q "$OUTPUT" $JUNK/file && echo "$OUTPUT" >> $JUNK/file || continue #skip duplicate URLs
        FUNC "$@" &
        echo "$!" >> $JUNK/pid
        echo $! >> $JUNK/pids
    done <<< $output; exit) &
    echo "$!" >> $JUNK/pid
    echo $! >> $JUNK/pids
done < $JUNK/url; exit) &
echo "$!" >> $JUNK/pid
echo $! >> $JUNK/pids
while grep -owq -f "$JUNK/pid" <<< $(ls /proc); do printf %b ":: working...\\r"; sleep 5; done
